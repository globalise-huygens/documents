"""
Import archival hierarchy from JSON into the database.

This script imports Series (sets) and Inventory records from the JSON
generated by extract_archival_hierarchy.py.
"""

import json
from datetime import datetime, date
from typing import Optional
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from models import Base, Series, Inventory, InventoryTitle


def parse_date(date_str: str) -> Optional[date]:
    """
    Parse a date string into a datetime.date object.

    Args:
        date_str: Date string (YYYY, YYYY-MM-DD, etc.)

    Returns:
        datetime.date or None
    """
    if not date_str:
        return None

    # Try full ISO format first
    try:
        return datetime.strptime(date_str, "%Y-%m-%d").date()
    except ValueError:
        pass

    # Try year-month format
    try:
        return datetime.strptime(date_str, "%Y-%m").date()
    except ValueError:
        pass

    # Try year only - use January 1st
    try:
        return datetime.strptime(date_str, "%Y").date()
    except ValueError:
        pass

    return None


def import_hierarchy(
    json_path: str,
    database_url: str = "sqlite:///globalise_documents.db",
    commit_interval_series: int = 200,
    commit_interval_relationships: int = 2000,
):
    """Import archival hierarchy into database.

    Hierarchy-only: only creates missing Series records and links EXISTING inventories
         (matched by inventory_number) to the appropriate Series. No new inventories or titles
         are created.

    Args:
        json_path: Path to the JSON file with archival hierarchy.
        database_url: SQLAlchemy database URL.
        commit_interval_series: Batch size for committing series inserts.
        commit_interval_relationships: Batch size for committing relationship inserts.
    """
    # Load JSON data
    print(f"Loading data from {json_path}...")
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(f"Found {len(data['series'])} series")
    print(f"Found {len(data['inventories'])} inventories (JSON)")
    print(f"Found {len(data['inventory_series'])} relationships (JSON)")

    # Create database connection
    engine = create_engine(database_url, echo=False)
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()

    try:
        # --- Import / Ensure Series ---
        print("\nImporting (or ensuring) series...")
        existing_series_ids = {s.id for s in session.query(Series.id)}
        series_map = {}

        # Sort by path depth to ensure parents are created before children
        sorted_series = sorted(data["series"], key=lambda s: s["path"].count("/"))

        created_series = 0
        for i, series_data in enumerate(sorted_series, 1):
            sid = series_data["id"]
            if sid in existing_series_ids:
                # Load existing
                series_obj = session.get(Series, sid)
                if series_obj is not None:
                    series_map[sid] = series_obj
                else:
                    # Inconsistent state: id reported but object missing
                    print(
                        f"  Warning: series id {sid} listed but not found; recreating."
                    )
                if series_obj is not None:
                    continue

            series = Series(
                id=sid,
                title=series_data["title"],
                part_of_id=series_data.get("part_of_id"),
            )
            session.add(series)
            series_map[sid] = series
            created_series += 1

            if created_series % commit_interval_series == 0:
                print(
                    f"  Created {created_series} new series (processed {i}/{len(sorted_series)})..."
                )
                session.commit()

        session.commit()
        print(
            f"✓ Series ensured. New: {created_series}, Total now: {session.query(Series).count()}"
        )

        # --- Hierarchy-only: link existing inventories ---
        print("\nLinking existing inventories to series (hierarchy-only mode)...")

        # Build map from JSON inventory id -> inventory_number
        json_inv_id_to_number = {
            inv["id"]: inv["inventory_number"] for inv in data["inventories"]
        }

        # Build map of existing inventories by inventory_number
        existing_inventories = {
            inv.inventory_number: inv for inv in session.query(Inventory).all()
        }

        linked = 0
        skipped_missing_inventory = 0
        processed_rel = 0

        for rel in data["inventory_series"]:
            processed_rel += 1
            json_inv_id = rel["inventory_id"]
            series_id = rel["series_id"]

            inv_number = json_inv_id_to_number.get(json_inv_id)
            if inv_number is None:
                skipped_missing_inventory += 1
                continue

            inv_obj = existing_inventories.get(inv_number)
            if not inv_obj:
                skipped_missing_inventory += 1
                continue

            series_obj = series_map.get(series_id)
            if not series_obj:
                # Series might not have been created due to missing parent; skip
                continue

            # Avoid duplicate association (SQLAlchemy will manage, but we can check)
            if series_obj not in inv_obj.member_of_series:
                inv_obj.member_of_series.append(series_obj)
                linked += 1

            if processed_rel % commit_interval_relationships == 0:
                print(
                    f"  Processed {processed_rel} relationships; linked {linked}; skipped {skipped_missing_inventory} (inventory not found)."
                )
                session.commit()

        session.commit()
        print(
            f"✓ Hierarchy linking complete. Linked {linked} relationships. Skipped {skipped_missing_inventory} due to missing inventories."
        )

        print("\n✓ Import completed successfully!")

        # Print some statistics
        print("\n=== Database Statistics ===")
        print(f"Total Series: {session.query(Series).count()}")
        print(f"Total Inventories: {session.query(Inventory).count()}")
        print(f"Total Inventory Titles: {session.query(InventoryTitle).count()}")

        # Show sample data
        print("\n=== Sample Series ===")
        for series in session.query(Series).limit(5):
            parent = (
                f" (parent: {series.part_of.title[:40]}...)" if series.part_of else ""
            )
            print(f"  - {series.title[:60]}...{parent}")

        # Sample of existing inventories now with relationships
        print("\n=== Sample Existing Inventories with Linked Series ===")
        for inv in (
            session.query(Inventory).filter(Inventory.member_of_series.any()).limit(5)
        ):
            title = inv.titles[0].title[:60] if inv.titles else "No title"
            series_count = len(inv.member_of_series)
            print(
                f"  - {inv.inventory_number}: {title}... ({series_count} linked series)"
            )

    except Exception as e:
        print(f"\n✗ Error during import: {e}")
        session.rollback()
        raise
    finally:
        session.close()


def import_series_only(
    json_path: str,
    database_url: str = "sqlite:///globalise_documents.db",
    include_all_series: bool = False,
    commit_interval: int = 200,
) -> None:
    """Import only the Series hierarchy based on inventories present in DB.

    Steps:
      1) Query all inventory numbers present in the database.
      2) Add the series (create Series records if missing).
      3) Add the series-of-series (set parent links part_of_id).

    By default, only series relevant to existing inventories are created
    (i.e., series referenced by relationships for inventories present in DB,
     plus all ancestor series up to the root). Set include_all_series=True to
    import all series regardless of inventory presence.
    """
    # Load JSON data
    print(f"Loading data from {json_path}...")
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(f"Series in JSON: {len(data['series'])}")
    print(f"Inventories in JSON: {len(data['inventories'])}")
    print(f"Relationships in JSON: {len(data['inventory_series'])}")

    # DB connection
    engine = create_engine(database_url, echo=False)
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()

    try:
        # 1) Query all inventory numbers present in the database
        existing_numbers = {inv.inventory_number for inv in session.query(Inventory)}
        print(f"Existing inventories in DB: {len(existing_numbers)}")

        # If include_all_series, we will import the full series list
        # Else, compute the relevant series based on present inventories
        series_json_by_id = {s["id"]: s for s in data["series"]}

        relevant_series_ids = set()
        if include_all_series:
            relevant_series_ids = set(series_json_by_id.keys())
        else:
            # Map JSON inv id -> inventory_number from JSON
            json_inv_id_to_number = {
                inv["id"]: inv["inventory_number"] for inv in data["inventories"]
            }

            # Start with series referenced by relationships where inventory exists in DB
            for rel in data["inventory_series"]:
                inv_num = json_inv_id_to_number.get(rel["inventory_id"])  # may be None
                if inv_num and inv_num in existing_numbers:
                    relevant_series_ids.add(rel["series_id"])

            # Add all ancestors (series-of-series up to root) so parent links are valid
            def add_ancestors(series_id: str):
                current_id = series_id
                visited = set()
                while current_id and current_id not in visited:
                    visited.add(current_id)
                    s = series_json_by_id.get(current_id)
                    if not s:
                        break
                    parent_id = s.get("part_of_id")
                    if parent_id:
                        relevant_series_ids.add(parent_id)
                        current_id = parent_id
                    else:
                        break

            for sid in list(relevant_series_ids):
                add_ancestors(sid)

        print(f"Relevant series to ensure: {len(relevant_series_ids)}")

        # 2) Add the series (create if missing, without worrying about parent order)
        existing_series_ids = {s.id for s in session.query(Series.id)}
        created = 0
        processed = 0
        for sid in relevant_series_ids:
            processed += 1
            if sid in existing_series_ids:
                continue
            s_json = series_json_by_id.get(sid)
            if not s_json:
                continue
            s_obj = Series(
                id=s_json["id"],
                title=s_json["title"],
                part_of_id=None,  # set later in step 3
            )
            session.add(s_obj)
            created += 1
            if created % commit_interval == 0:
                print(
                    f"  Created {created} series (processed {processed}/{len(relevant_series_ids)})..."
                )
                session.commit()

        session.commit()
        print(
            f"✓ Series ensured. New created: {created}. Total now: {session.query(Series).count()}"
        )

        # 3) Add the series-of-series (set parent relationships)
        # We can now safely set part_of_id because all relevant parents were also ensured.
        print("\nSetting parent relationships (series-of-series)...")
        updated_links = 0
        processed = 0
        for sid in relevant_series_ids:
            processed += 1
            s_json = series_json_by_id.get(sid)
            if not s_json:
                continue
            parent_id = s_json.get("part_of_id")

            s_obj = session.get(Series, sid)
            if s_obj is None:
                continue

            # Only set when different to avoid unnecessary writes
            if (parent_id or None) != (s_obj.part_of_id or None):
                s_obj.part_of_id = parent_id
                updated_links += 1
                if updated_links % (commit_interval * 2) == 0:
                    print(
                        f"  Updated {updated_links} parent links (processed {processed}/{len(relevant_series_ids)})..."
                    )
                    session.commit()

        session.commit()
        print(f"✓ Parent relationships set. Updated {updated_links} links.")

        print("\n✓ Series-only import completed successfully!")
    except Exception as e:
        print(f"\n✗ Error during series-only import: {e}")
        session.rollback()
        raise
    finally:
        session.close()


def main():
    """Main function."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Import archival hierarchy from JSON into database"
    )
    parser.add_argument(
        "json_file",
        help="Path to JSON file with archival hierarchy",
    )
    parser.add_argument(
        "--database",
        default="sqlite:///globalise_documents.db",
        help="Database URL (default: sqlite:///globalise_documents.db)",
    )
    parser.add_argument(
        "--series-only",
        action="store_true",
        help="Only import series and set parent relationships; filter to inventories present in DB by default",
    )
    parser.add_argument(
        "--all-series",
        action="store_true",
        help="When used with --series-only, import all series regardless of inventory presence",
    )

    args = parser.parse_args()

    if args.series_only:
        import_series_only(
            args.json_file,
            args.database,
            include_all_series=args.all_series,
        )
    else:
        import_hierarchy(
            args.json_file,
            args.database,
        )


if __name__ == "__main__":
    main()
